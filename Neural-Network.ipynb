{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 124,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_biases(n_x, n_h, n_y):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    n_x -- neurons in input layer\n",
        "    n_h -- neurons in hidden layer\n",
        "    n_y -- neurons in output layer\n",
        "    \n",
        "    Returns:\n",
        "    weights --\n",
        "    biases --\n",
        "    \"\"\"\n",
        "    \n",
        "    weights = {}\n",
        "    weights[\"W1\"] = np.random.randn(n_h, n_x) * 0.001\n",
        "    weights[\"W2\"] = np.random.randn(n_y, n_h) * 0.001\n",
        "    \n",
        "    biases = {}\n",
        "    biases[\"b1\"] = np.zeros((n_h, 1))\n",
        "    biases[\"b2\"] = np.zeros((n_y, 1))\n",
        "  \n",
        "    return weights, biases"
      ],
      "outputs": [],
      "execution_count": 125,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU(Z, threshold = 0):\n",
        "    A = np.multiply(Z, (Z > threshold))\n",
        "    return A"
      ],
      "outputs": [],
      "execution_count": 126,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(Z):\n",
        "    A = 1 / (1 + np.exp(-Z))\n",
        "    return A"
      ],
      "outputs": [],
      "execution_count": 127,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forwardpropagate(X, weights, biases):\n",
        "    \n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- (m x n_x) dimensional input matrix\n",
        "    weights --\n",
        "        weights[\"W1\"] -- (n_h x n_x) matrix\n",
        "        weights[\"W2\"] -- (n_y x n_h) matrix\n",
        "    biases --\n",
        "        biases[\"b1\"] -- (n_h x 1) matrix\n",
        "        biases[\"b2\"] -- (n_y x 1) matrix\n",
        "        \n",
        "    Returns:\n",
        "    activations --\n",
        "        activations[\"A0\"] -- (n_x x m) matrix\n",
        "        activations[\"A1\"] -- (n_h x m) matrix\n",
        "        activations[\"A2\"] -- (n_y x m) matrix\n",
        "    \"\"\"\n",
        "    \n",
        "   \n",
        "    \n",
        "    W1, W2 = weights[\"W1\"], weights[\"W2\"]\n",
        "    b1, b2 = biases[\"b1\"], biases[\"b2\"]\n",
        "    m, n_x = X.shape\n",
        "    n_h = b1.shape[0]\n",
        "    n_y = b2.shape[0]\n",
        "    \n",
        "    A0 = X.T\n",
        "    \n",
        "    Z1 = np.dot(W1, A0) + b1\n",
        "    A1 = ReLU(Z1)\n",
        "    \n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    \n",
        "    activations = {}\n",
        "    assert(A0.shape == (n_x, m))\n",
        "    activations[\"A0\"] = A0\n",
        "    assert(A1.shape == (n_h, m))\n",
        "    activations[\"A1\"] = A1\n",
        "    assert(A2.shape == (n_y, m))\n",
        "    activations[\"A2\"] = A2\n",
        "    \n",
        "    return activations\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 128,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagate(weights, biases, activations, Y):\n",
        "    W1, W2  = weights[\"W1\"], weights[\"W2\"]\n",
        "    b1, b2 = biases[\"b1\"], biases[\"b2\"]\n",
        "    A0, A1, A2 = activations[\"A0\"], activations[\"A1\"], activations[\"A2\"]\n",
        "    m = Y.shape[1]\n",
        "    \n",
        "    dZ2 = A2 - Y.T\n",
        "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
        "    assert(W2.shape == dW2.shape)\n",
        "    db2 = (1 / m) * np.sum(dZ2, axis = 1, keepdims = True)\n",
        "    assert(b2.shape == db2.shape)\n",
        "    \n",
        "    dZ1 = np.dot(np.dot(W2.T, dZ2), (1 - np.power(A1, 2)))\n",
        "    dW1 = (1 / m) * np.dot(dZ1, A0.T)\n",
        "    assert(W1.shape == dW1.shape)\n",
        "    db1 = (1 / m) * np.sum(dZ1, axis = 1, keepdims = True)\n",
        "    assert(b1.shape == db1.shape)\n",
        "    \n",
        "    \n",
        "    weight_gradients = {}\n",
        "    weight_gradients[\"dW1\"] = dW1\n",
        "    weight_gradients[\"dW2\"] = dW2\n",
        "    \n",
        "    bias_gradients = {}\n",
        "    bias_gradients[\"db1\"] = db1\n",
        "    bias_gradients[\"db2\"] = db2\n",
        "    \n",
        "    return weight_gradients, bias_gradients"
      ],
      "outputs": [],
      "execution_count": 151,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# n_x = X.shape[1]\n",
        "# n_h = 3\n",
        "# n_y = Y.shape[1]\n",
        "# weights, biases = initialize_weights_biases(n_x, n_h, n_y)\n",
        "# activations = forwardpropagate(X, weights, biases)\n",
        "# backpropagate(weights, biases, activations, Y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 153,
          "data": {
            "text/plain": [
              "({'dW1': array([[-0.04857314, -0.06476419],\n",
              "         [ 0.06369571,  0.08492762],\n",
              "         [-0.00036558, -0.00048744]]),\n",
              "  'dW2': array([[ 0.        , -0.01179775, -0.00378254]])},\n",
              " {'db1': array([[-0.01619106],\n",
              "         [ 0.02123192],\n",
              "         [-0.00012186]]), 'db2': array([[-4.5000027]])})"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 153,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[1, 2],\n",
        "             [3, 4],\n",
        "             [5, 6]])\n",
        "print(X)\n",
        "Y = np.array([[1],\n",
        "             [2],\n",
        "             [3]])\n",
        "print(Y)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "[[1]\n",
            " [2]\n",
            " [3]]\n"
          ]
        }
      ],
      "execution_count": 130,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Cost Function (Unregularized) ###\n",
        "\n\n$$J(W, X, Y) = - \\frac{1}{m} \\sum\\limits_{k=1}^K\\sum\\limits_{i=1}^m Y_k^{(i)}log(h_{W}(x^{(i)})_k) + (1 - Y_k^{(i)} )log(1- h_W(x^{(i)})_k) $$"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost_logistic(yhat, Y):\n",
        "    assert(yhat.shape == Y.shape)\n",
        "    \n",
        "    m = Y.shape[0]\n",
        "    \n",
        "    cost = (-1 / m) * np.sum(np.dot(Y.T, np.log(yhat)) + np.dot((1 - Y).T, np.log(1-yhat)))\n",
        "    return cost\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 131,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_nn(X, Y, n_h, learning_rate = 0.005, num_iterations = 20):\n",
        "    \n",
        "    n_x = X.shape[1]\n",
        "    n_y = Y.shape[1]\n",
        "    \n",
        "    weights, biases = initialize_weights_biases(n_x, n_h, n_y)\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "        activations = forwardpropagate(X, weights, biases)\n",
        "        yhat = activations[\"A2\"].T\n",
        "        cost = compute_cost_logistic(yhat, Y)\n",
        "        weight_gradients, bias_gradients = backpropagate(weights, biases, activations, Y)\n",
        "        print(\"Cost (iteration \" + str(i) + \") = \" + str(cost))\n",
        "        dW1 = weight_gradients[\"dW1\"]\n",
        "        dW2 = weight_gradients[\"dW2\"]\n",
        "        db1 = bias_gradients[\"db1\"]\n",
        "        db2 = bias_gradients[\"db2\"]\n",
        "        \n",
        "        weights[\"W1\"] -= learning_rate * dW1\n",
        "        weights[\"W2\"] -= learning_rate * dW2\n",
        "        biases[\"b1\"] -=  learning_rate * db1\n",
        "        biases[\"b2\"] -= learning_rate * db2\n",
        "        \n",
        "    \n",
        "#     print(\"Weights\")\n",
        "#     print(weights[\"W1\"])\n",
        "#     print(weights[\"W2\"])\n",
        "    \n",
        "#     print(\"Biases\")\n",
        "#     print(\"b1\")\n",
        "#     print(biases[\"b1\"])\n",
        "#     print(\"b2\")\n",
        "#     print(biases[\"b2\"])\n",
        "    \n",
        "#     print(\"Activations\")\n",
        "#     print(\"A0\")\n",
        "#     print(activations[\"A0\"])\n",
        "#     print(\"A1\")\n",
        "#     print(activations[\"A1\"])\n",
        "#     print(\"A2\")\n",
        "#     print(activations[\"A2\"])"
      ],
      "outputs": [],
      "execution_count": 175,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_nn(X, Y, 3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost (iteration 0) = 0.693150642041\n",
            "Cost (iteration 1) = 0.659458543846\n",
            "Cost (iteration 2) = 0.626021932101\n",
            "Cost (iteration 3) = 0.59283505831\n",
            "Cost (iteration 4) = 0.559895403259\n",
            "Cost (iteration 5) = 0.527200368029\n",
            "Cost (iteration 6) = 0.49474709565\n",
            "Cost (iteration 7) = 0.462532358894\n",
            "Cost (iteration 8) = 0.430552401538\n",
            "Cost (iteration 9) = 0.398802709838\n",
            "Cost (iteration 10) = 0.36727768157\n",
            "Cost (iteration 11) = 0.335970146078\n",
            "Cost (iteration 12) = 0.30487066861\n",
            "Cost (iteration 13) = 0.273966543163\n",
            "Cost (iteration 14) = 0.243240336482\n",
            "Cost (iteration 15) = 0.212667786531\n",
            "Cost (iteration 16) = 0.182214774498\n",
            "Cost (iteration 17) = 0.151832970386\n",
            "Cost (iteration 18) = 0.12145358535\n",
            "Cost (iteration 19) = 0.090978432248\n"
          ]
        }
      ],
      "execution_count": 176,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n\n\n\n\n\n\n\n\n"
      ],
      "outputs": [],
      "execution_count": 134,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.4.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}